# 24G显存微调一个迷你大语言模型

## 为什么想写一个这样的仓库？

当下一些高校计算资源匮乏，严重落后于业界，实验室内所做研究多为屎上雕花，无法与业界接轨，让一些想接触前沿技术（如LLM）的学生只能望而却步。

不甘于此，我想在有限的资源下学习一些相关的算法，遂~~骗~~（炼丹人的事怎么能叫骗呢）借了实验室的24G显存的GPU，尝试微调一个迷你大语言模型，试图搞清楚训练的流程。

[相关博客](https://blog.fyz666.xyz/categories/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/)